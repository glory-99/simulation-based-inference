{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.optimize import fsolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4519887577232509\n",
      "1.452137612552812\n"
     ]
    }
   ],
   "source": [
    "def compute_int(y, sigma=1):\n",
    "    return np.sqrt(np.pi/2) * sigma * (math.erf((y+3)/(sigma*np.sqrt(2))) - math.erf((y-3)/(sigma*np.sqrt(2))))\n",
    "print(compute_int(-2.8))\n",
    "x = np.linspace(-3, 3, 10000)\n",
    "print(0.0006 * np.sum(np.exp(-np.square(x+2.8)/2)[:9999]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z_i \\sim Ber(\\theta)$\\\n",
    "$\\beta_i \\sim U(-a,a)$\\\n",
    "$Y_i|Z_i, \\beta_i \\sim N(z_i \\circ \\beta_i, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "compute normalization constant\n",
    "'''\n",
    "def compute_c(y, theta, a, sigma):\n",
    "    c = 2*a * (1-theta) * np.exp(-y**2 / (2 * sigma**2)) \\\n",
    "    + theta * np.sqrt(np.pi/2) * sigma * \\\n",
    "    (math.erf((y+a)/(sigma*np.sqrt(2))) - math.erf((y-a)/(sigma*np.sqrt(2))))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "compute the cumulative probablity of the marginal distribution of beta\n",
    "'''\n",
    "def cumulative_prob(t, y, norm_c, theta, a, sigma):\n",
    "    assert t>=-a and t<=a\n",
    "    prob = (1-theta) * np.exp(-y**2 / (2 * sigma**2)) * (t+a) / norm_c \\\n",
    "        + theta * np.sqrt(np.pi/2) * sigma * \\\n",
    "            (math.erf((y+a)/(sigma*np.sqrt(2))) - math.erf((y-t)/(sigma*np.sqrt(2)))) / norm_c\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876858004982628\n"
     ]
    }
   ],
   "source": [
    "y = 2\n",
    "theta = 0.05\n",
    "a = 3\n",
    "sigma = 1\n",
    "c = compute_c(y, theta, a, sigma)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_prob(-3, y, c, theta, a, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_prob(3, y, c, theta, a, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029324893165522226"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_prob(-2.8, y, c, theta, a, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.82949636])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsolve(lambda x: cumulative_prob(x, y, c, theta, a, sigma) - 0.025, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.86380276])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsolve(lambda x: cumulative_prob(x, y, c, theta, a, sigma) - 0.975, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $a$ is too small, then the posterior CI will always contain 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12540218421537278\n"
     ]
    }
   ],
   "source": [
    "y = 5\n",
    "theta = 0.05\n",
    "a = 10\n",
    "sigma = 1\n",
    "c = compute_c(y, theta, a, sigma)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_prob(-10, y, c, theta, a, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_prob(10, y, c, theta, a, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0339417])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsolve(lambda x: cumulative_prob(x, y, c, theta, a, sigma) - 0.025, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.96118773])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsolve(lambda x: cumulative_prob(x, y, c, theta, a, sigma) - 0.975, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z_i \\sim Ber(\\theta)$\\\n",
    "$\\beta_i|Z_i=1 \\sim U(-a,a)$\\\n",
    "$\\beta_i|Z_i=0 \\sim \\delta (0)$\\\n",
    "$Y_i|\\beta_i \\sim N( \\beta_i, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "compute normalization constant\n",
    "'''\n",
    "def compute_c(y, theta, a, sigma):\n",
    "    c = 2*a * (1-theta) * np.exp(-y**2 / (2 * sigma**2)) \\\n",
    "    + theta * np.sqrt(np.pi/2) * sigma * \\\n",
    "    (math.erf((y+a)/(sigma*np.sqrt(2))) - math.erf((y-a)/(sigma*np.sqrt(2))))\n",
    "    return c / (2*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "compute the cumulative probablity of the marginal distribution of beta\n",
    "'''\n",
    "def cumulative_prob(t, y, norm_c, theta, a, sigma):\n",
    "    assert t>=-a and t<=a\n",
    "    if t>=0:\n",
    "        prob = (1-theta) * np.exp(-y**2 / (2 * sigma**2)) / norm_c \\\n",
    "            + theta * np.sqrt(np.pi/2) * sigma * \\\n",
    "                (math.erf((y+a)/(sigma*np.sqrt(2))) - math.erf((y-t)/(sigma*np.sqrt(2)))) / (2 * a * norm_c)\n",
    "    elif t<0:\n",
    "        prob = theta * np.sqrt(np.pi/2) * sigma * \\\n",
    "                (math.erf((y+a)/(sigma*np.sqrt(2))) - math.erf((y-t)/(sigma*np.sqrt(2)))) / (2 * a * norm_c)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.146143000830438\n"
     ]
    }
   ],
   "source": [
    "y = 2\n",
    "theta = 0.05\n",
    "a = 3\n",
    "sigma = 1\n",
    "c = compute_c(y, theta, a, sigma)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "print(cumulative_prob(-3, y, c, theta, a, sigma))\n",
    "print(cumulative_prob(3, y, c, theta, a, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0031752871211294924\n",
      "0.8829963121990655\n"
     ]
    }
   ],
   "source": [
    "print(cumulative_prob(-0.01, y, c, theta, a, sigma))\n",
    "print(cumulative_prob(0, y, c, theta, a, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006585260176902366\n"
     ]
    }
   ],
   "source": [
    "y = 4\n",
    "theta = 0.05\n",
    "a = 10\n",
    "sigma = 1\n",
    "c = compute_c(y, theta, a, sigma)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(cumulative_prob(-10, y, c, theta, a, sigma))\n",
    "print(cumulative_prob(10, y, c, theta, a, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048424505337170534\n"
     ]
    }
   ],
   "source": [
    "print(cumulative_prob(0, y, c, theta, a, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998715430366437\n"
     ]
    }
   ],
   "source": [
    "print(cumulative_prob(7, y, c, theta, a, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rng\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator_eye(object):\n",
    "    def __init__(self, p, theta, beta_range) -> None:\n",
    "        self.p = p \n",
    "        self.theta = theta \n",
    "        self.beta_range = beta_range \n",
    "        self.X = np.eye(p)\n",
    "    \n",
    "    def generate_samples(self, n):\n",
    "        scale = self.beta_range[1] - self.beta_range[0]\n",
    "        theta = np.ones((n, self.p)) * self.theta\n",
    "        gamma = rng.binomial(1, theta)\n",
    "        beta = np.zeros((n, self.p))\n",
    "        beta[gamma == 1] = rng.rand(np.sum(gamma == 1)) * scale + self.beta_range[0]\n",
    "        beta[gamma == 0] = 0. \n",
    "        Y = beta@self.X.T + rng.randn(n, self.N)\n",
    "        return gamma, beta, Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_eye = Generator_eye(p=200, theta=0.05, beta_range=(-10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.seed(0)\n",
    "gamma_train, beta_train, Y_train = generator_eye.generate_samples(1000000)\n",
    "gamma_val, beta_val, Y_val = generator_eye.generate_samples(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = Y_train.mean(0)\n",
    "std = Y_train.std(0)\n",
    "Y_train = (Y_train - mean) / std \n",
    "Y_val = (Y_val - mean) / std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.seed(1)\n",
    "gamma_test, beta_test, Y_test = generator_eye.generate_samples(10000)\n",
    "Y_test = (Y_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, N, p):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(N, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 2048)\n",
    "        self.fc4 = nn.Linear(2048, 1024)\n",
    "        self.fc5 = nn.Linear(1024, p)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mseloss = nn.MSELoss()\n",
    "        self.bceloss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input):\n",
    "        u = self.relu(self.fc1(input))\n",
    "        u = self.relu(self.fc2(u))\n",
    "        u = self.relu(self.fc3(u))\n",
    "        u = self.relu(self.fc4(u))\n",
    "        output = self.fc5(u)\n",
    "        return output\n",
    "\n",
    "    def get_mseloss(self, data, targ):\n",
    "        output = self.forward(data)\n",
    "        loss = self.mseloss(output, targ)\n",
    "        return loss \n",
    "    \n",
    "    def get_bceloss(self, data, targ):\n",
    "        output = self.forward(data)\n",
    "        loss = self.bceloss(output, targ)\n",
    "        return loss \n",
    "\n",
    "    def get_quanloss(self, data, targ, tau):\n",
    "        output = self.forward(data)\n",
    "        errs = targ - output \n",
    "        loss = torch.mean(torch.max((tau-1)*errs, tau*errs))\n",
    "        return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    " loss_type: 'mse' for posterior mean, 'bce' for predicting whether beta is 0, 'quantile' for posterior quantile.\n",
    "q: Only used when loss_type is 'quantile', q quantile.\n",
    "'''\n",
    "def train_epoch(model, optimizer, train_data, train_labels, batch_size, loss_type, q):\n",
    "    model.train()\n",
    "    n = train_data.shape[0]\n",
    "    train_loss = 0.\n",
    "    for i in range(math.ceil(n/batch_size)):\n",
    "        data = torch.from_numpy(train_data[(i*batch_size):min((i+1)*batch_size, n-1)]).type(torch.float).to(device)\n",
    "        targ = torch.from_numpy(train_labels[(i*batch_size):min((i+1)*batch_size, n-1)]).type(torch.float).to(device)\n",
    "        if loss_type == 'mse':\n",
    "            loss = model.get_mseloss(data, targ)\n",
    "        elif loss_type == 'bce':\n",
    "            loss = model.get_bceloss(data, targ)\n",
    "        elif loss_type == 'quantile':\n",
    "            loss = model.get_quanloss(data, targ, q)\n",
    "        train_loss += loss.item() * data.shape[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss/n \n",
    "\n",
    "def model_test(model, test_data, test_labels, loss_type='mse', q=0.5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = torch.from_numpy(test_data).type(torch.float).to(device)\n",
    "        targ = torch.from_numpy(test_labels).type(torch.float).to(device)\n",
    "        if loss_type == 'mse':\n",
    "            loss = model.get_mseloss(data, targ)\n",
    "        elif loss_type == 'bce':\n",
    "            loss = model.get_bceloss(data, targ)\n",
    "        elif loss_type == 'quantile':\n",
    "            loss = model.get_quanloss(data, targ, q)\n",
    "    return loss.item()\n",
    "\n",
    "def train_model(model, lr, batch_size, epochs, train_data, train_labels, loss_type='mse', q=0.5, val_data=None, val_labels=None, early_stop=5):\n",
    "    assert loss_type in ['mse', 'bce', 'quantile']\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    min_loss = 1e6\n",
    "    es_count = 0\n",
    "    for i in range(epochs):\n",
    "        train_loss = train_epoch(model, optimizer, train_data, train_labels, batch_size, loss_type, q)\n",
    "        print('Epoch: {}'.format(i+1))\n",
    "        print('Train loss: {:.5f}'.format(train_loss))\n",
    "        train_losses.append(train_loss)\n",
    "        if isinstance(val_data, np.ndarray):\n",
    "            val_loss = model_test(model, val_data, val_labels, loss_type, q)\n",
    "            print('Val loss: {:.5f}'.format(val_loss))\n",
    "            val_losses.append(val_loss)\n",
    "            if val_loss <= min_loss:\n",
    "                min_loss = val_loss\n",
    "                es_count = 0\n",
    "            if es_count >= early_stop:\n",
    "                break\n",
    "            es_count += 1\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def predict(model, Y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = torch.from_numpy(Y).type(torch.float).to(device)\n",
    "        pred = model(data)\n",
    "    return pred.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss(train_losses, val_losses):\n",
    "    plt.plot(range(len(train_losses)), train_losses)\n",
    "    plt.plot(range(len(train_losses)), val_losses)\n",
    "    plt.legend(['train loss', 'val loss'], loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "def predict_class(model, Y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = torch.from_numpy(Y).type(torch.float).to(device)\n",
    "        pred = torch.sigmoid(model(data))\n",
    "    return pred.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 33.24183\n",
      "Val loss: 33.22535\n",
      "Epoch: 2\n",
      "Train loss: 33.09696\n",
      "Val loss: 33.09955\n",
      "Epoch: 3\n",
      "Train loss: 32.96765\n",
      "Val loss: 33.00992\n",
      "Epoch: 4\n",
      "Train loss: 32.88032\n",
      "Val loss: 32.95216\n",
      "Epoch: 5\n",
      "Train loss: 32.81909\n",
      "Val loss: 32.90902\n",
      "Epoch: 6\n",
      "Train loss: 32.77043\n",
      "Val loss: 32.86763\n",
      "Epoch: 7\n",
      "Train loss: 32.72477\n",
      "Val loss: 32.82511\n",
      "Epoch: 8\n",
      "Train loss: 32.68126\n",
      "Val loss: 32.78724\n",
      "Epoch: 9\n",
      "Train loss: 32.64445\n",
      "Val loss: 32.76188\n",
      "Epoch: 10\n",
      "Train loss: 32.61947\n",
      "Val loss: 32.74752\n",
      "Epoch: 11\n",
      "Train loss: 32.60234\n",
      "Val loss: 32.74432\n",
      "Epoch: 12\n",
      "Train loss: 32.58886\n",
      "Val loss: 32.74987\n",
      "Epoch: 13\n",
      "Train loss: 32.57552\n",
      "Val loss: 32.76115\n",
      "Epoch: 14\n",
      "Train loss: 32.56219\n",
      "Val loss: 32.76849\n",
      "Epoch: 15\n",
      "Train loss: 32.54930\n",
      "Val loss: 32.77956\n",
      "Epoch: 16\n",
      "Train loss: 32.53586\n",
      "Val loss: 32.79289\n"
     ]
    }
   ],
   "source": [
    "md = MLP(N=200, p=200).to(device)\n",
    "train_losses, val_losses = train_model(md, 0.001, 256, 80, Y_train, beta_train, val_data=Y_val, val_labels=beta_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 0.24972\n",
      "Val loss: 0.24457\n",
      "Epoch: 2\n",
      "Train loss: 0.24430\n",
      "Val loss: 0.24489\n",
      "Epoch: 3\n",
      "Train loss: 0.24420\n",
      "Val loss: 0.24418\n",
      "Epoch: 4\n",
      "Train loss: 0.24409\n",
      "Val loss: 0.24413\n",
      "Epoch: 5\n",
      "Train loss: 0.24403\n",
      "Val loss: 0.24410\n",
      "Epoch: 6\n",
      "Train loss: 0.24400\n",
      "Val loss: 0.24412\n",
      "Epoch: 7\n",
      "Train loss: 0.24397\n",
      "Val loss: 0.24414\n",
      "Epoch: 8\n",
      "Train loss: 0.24395\n",
      "Val loss: 0.24409\n",
      "Epoch: 9\n",
      "Train loss: 0.24394\n",
      "Val loss: 0.24403\n",
      "Epoch: 10\n",
      "Train loss: 0.24393\n",
      "Val loss: 0.24408\n",
      "Epoch: 11\n",
      "Train loss: 0.24392\n",
      "Val loss: 0.24404\n",
      "Epoch: 12\n",
      "Train loss: 0.24391\n",
      "Val loss: 0.24403\n",
      "Epoch: 13\n",
      "Train loss: 0.24390\n",
      "Val loss: 0.24400\n",
      "Epoch: 14\n",
      "Train loss: 0.24389\n",
      "Val loss: 0.24400\n",
      "Epoch: 15\n",
      "Train loss: 0.24389\n",
      "Val loss: 0.24400\n",
      "Epoch: 16\n",
      "Train loss: 0.24388\n",
      "Val loss: 0.24401\n",
      "Epoch: 17\n",
      "Train loss: 0.24388\n",
      "Val loss: 0.24404\n",
      "Epoch: 18\n",
      "Train loss: 0.24387\n",
      "Val loss: 0.24405\n",
      "Epoch: 19\n",
      "Train loss: 0.24387\n",
      "Val loss: 0.24405\n"
     ]
    }
   ],
   "source": [
    "md_q025 = MLP(N=200, p=200).to(device)\n",
    "train_losses, val_losses = train_model(md_q025, 0.001, 256, 100, Y_train, beta_train, loss_type='quantile', q=0.025, val_data=Y_val, val_labels=beta_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss: 0.24983\n",
      "Val loss: 0.24426\n",
      "Epoch: 2\n",
      "Train loss: 0.24429\n",
      "Val loss: 0.24434\n",
      "Epoch: 3\n",
      "Train loss: 0.24419\n",
      "Val loss: 0.24399\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5648\\3609076807.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmd_q975\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmd_q975\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'quantile'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.975\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mY_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5648\\2064112158.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, lr, batch_size, epochs, train_data, train_labels, loss_type, q, val_data, val_labels, early_stop)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mes_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train loss: {:.5f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5648\\2064112158.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, optimizer, train_data, train_labels, batch_size, loss_type, q)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mtarg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mloss_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'mse'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "md_q975 = MLP(N=200, p=200).to(device)\n",
    "train_losses, val_losses = train_model(md_q975, 0.001, 256, 100, Y_train, beta_train, loss_type='quantile', q=0.975, val_data=Y_val, val_labels=beta_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_p(beta, y, theta, sigma):\n",
    "    return theta * np.exp(-(y-beta)**2 / (2 * sigma**2)) + (1-theta) * np.exp(-y**2 / (2 * sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.linspace(-3, 3, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = compute_p(beta, 2, 0.05, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998896233895808"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0006 * np.sum(p[:9999]) / compute_c(2, 0.05, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51279774, 0.62133786],\n",
       "       [0.0377208 , 0.0794336 ],\n",
       "       [0.48984867, 0.19415153]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng.rand(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28f8cf0a8a4d3996c532b07e251eb4af62f7beb2b6ca98348312838517986615"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
